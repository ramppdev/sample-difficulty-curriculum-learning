{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_selector = [\"curriculum.scoring.type\", \"curriculum.type\", \"test_accuracy\"]\n",
    "_baseline_sizes = [1, 3, 5, 15]\n",
    "_column_mapping = {\n",
    "    \"curriculum.scoring.type\": \"SF\",\n",
    "    \"curriculum.type\": \"Type\",\n",
    "    \"test_accuracy\": \"Accuracy\",\n",
    "}\n",
    "_sf_mapping = {\n",
    "    \"Predefined\": \"C-Score\",\n",
    "    \"CELoss\": \"CELoss\",\n",
    "    \"CumulativeAccuracy\": \"CumAcc\",\n",
    "    \"PredictionDepth\": \"PD\",\n",
    "    \"TransferTeacher\": \"TT\",\n",
    "    \"Random\": \"Random\",\n",
    "}\n",
    "\n",
    "\n",
    "def read_pacing_metrics(path: str, subdir: str = \"summary\") -> pd.DataFrame:\n",
    "    metrics_df = pd.read_csv(f\"{path}/{subdir}/metrics.csv\")\n",
    "    config_df = pd.read_csv(f\"{path}/{subdir}/config.csv\")\n",
    "    df = pd.merge(metrics_df, config_df, on=\"run_name\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_baseline_runs(df: pd.DataFrame, dataset: str) -> pd.DataFrame:\n",
    "    df = df[~df[\"curriculum\"].notnull()]\n",
    "    df = df[df[\"model\"] == \"EfficientNet-B0\"]\n",
    "    optim = \"Adam\" if dataset == \"cifar\" else \"SAM-SGD-M9\"\n",
    "    lr = 0.001 if dataset == \"cifar\" else 0.01\n",
    "    df = df[(df[\"optimizer\"] == optim) & (df[\"learning_rate\"] == lr)]\n",
    "    df = df[_selector].sort_values(\"test_accuracy\", ascending=False)\n",
    "    records = []\n",
    "    for s in _baseline_sizes:\n",
    "        records.append(df.head(s).mean())\n",
    "    df = pd.DataFrame(records).fillna(\"--\")\n",
    "    df[\"curriculum.type\"] = [f\"B{i}\" for i in _baseline_sizes]\n",
    "    df.rename(columns=_column_mapping, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_pacing_runs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def _assign_ordering_type(row) -> str:\n",
    "        if row[\"curriculum\"] == \"AntiCurriculum\":\n",
    "            return \"ACL\"\n",
    "        if row[\"curriculum.scoring.type\"] == \"Random\":\n",
    "            return \"RCL\"\n",
    "        return \"CL\"\n",
    "\n",
    "    df = df[df[\"curriculum\"].notnull()]\n",
    "    df = df[~df[\"curriculum.scoring\"].str.contains(\"\\+\")]\n",
    "    df = df[~df[\"run_name\"].str.contains(\"-S\\d\")]\n",
    "    df[\"curriculum.type\"] = df.apply(_assign_ordering_type, axis=1)\n",
    "    df = df[_selector].sort_values(\"test_accuracy\", ascending=False)\n",
    "    df.rename(columns=_column_mapping, inplace=True)\n",
    "    df = df.sort_values(\"Accuracy\", ascending=False).groupby(\"Type\").head(1)\n",
    "    df[\"SF\"] = df[\"SF\"].map(_sf_mapping)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_performance(dataset: str) -> pd.DataFrame:\n",
    "    summary_df = read_pacing_metrics(f\"results/{dataset}\")\n",
    "    baselines = select_baseline_runs(summary_df, dataset)\n",
    "\n",
    "    agg_df = read_pacing_metrics(f\"results/{dataset}\", \"agg_seed\")\n",
    "    pacing = select_pacing_runs(agg_df)\n",
    "    return (\n",
    "        pd.concat([baselines, pacing])\n",
    "        .sort_values(\"Accuracy\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_df = create_performance(\"cifar\")\n",
    "dcase_df = create_performance(\"dcase\")\n",
    "df = pd.concat([cifar_df, dcase_df], axis=1, keys=[\"CIFAR\", \"DCASE2020\"])\n",
    "os.makedirs(\"results/tables\", exist_ok=True)\n",
    "df.to_csv(\"results/tables/4_c_3_scoring_performance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CIFAR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DCASE2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>SF</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>SF</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-Score</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.844</td>\n",
       "      <td>--</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.839</td>\n",
       "      <td>TT</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--</td>\n",
       "      <td>B3</td>\n",
       "      <td>0.839</td>\n",
       "      <td>--</td>\n",
       "      <td>B3</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--</td>\n",
       "      <td>B5</td>\n",
       "      <td>0.838</td>\n",
       "      <td>--</td>\n",
       "      <td>B5</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--</td>\n",
       "      <td>B15</td>\n",
       "      <td>0.834</td>\n",
       "      <td>CELoss</td>\n",
       "      <td>ACL</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random</td>\n",
       "      <td>RCL</td>\n",
       "      <td>0.829</td>\n",
       "      <td>Random</td>\n",
       "      <td>RCL</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CELoss</td>\n",
       "      <td>ACL</td>\n",
       "      <td>0.829</td>\n",
       "      <td>--</td>\n",
       "      <td>B15</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CIFAR               DCASE2020              \n",
       "        SF Type Accuracy        SF Type Accuracy\n",
       "0  C-Score   CL    0.844        --   B1    0.583\n",
       "1       --   B1    0.839        TT   CL    0.577\n",
       "2       --   B3    0.839        --   B3    0.576\n",
       "3       --   B5    0.838        --   B5    0.571\n",
       "4       --  B15    0.834    CELoss  ACL    0.560\n",
       "5   Random  RCL    0.829    Random  RCL    0.558\n",
       "6   CELoss  ACL    0.829        --  B15    0.555"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
